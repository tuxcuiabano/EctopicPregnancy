# -*- coding: utf-8 -*-
"""ForFertility_NeuralEctopic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HlfE9Rc5yiqJrtm-paBww_6WYXxN-MYA
"""

import tensorflow as tf
from tensorflow import keras

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn import preprocessing
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import confusion_matrix
file = pd.read_csv('UltraFeatures.csv')
file.shape

#Separating the predictor variables
original_x = file.drop('BinaryOutcome', axis=1)
# removes the problem ValueError: could not convert string to float: 'No'
new_x = pd.get_dummies(original_x)
#Remove all NaN columns - MultinomialNB does not accept missing values encoded as NaN natively.
x = new_x.dropna(inplace=False, axis=1)

!pip install keras

import random
import keras
from keras import utils
random.seed (42)
np.random.seed(42)
tf.random.set_seed(42)
converted_x =  utils.to_categorical(x)
converted_x.shape

#Separating the target variables
y = pd.get_dummies(file['BinaryOutcome'])
#y = file['ComposedOutcome']
y.shape

converted_y = utils.to_categorical(y)
converted_y.shape

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)

from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout
from keras.optimizers import Adam

model = Sequential()
model.add(Dense(40, input_dim=67, kernel_initializer='normal', activation='relu'))
model.add(Dense(20, kernel_initializer='normal', activation='relu'))
model.add(Dense(20, kernel_initializer='normal', activation='relu'))
model.add(Dense(20, kernel_initializer='normal', activation='relu'))
model.add(Dense(2,kernel_initializer='normal', activation='sigmoid'))

optm = keras.optimizers.Adam(learning_rate=0.001)

model.compile(loss='categorical_crossentropy',optimizer = optm, metrics=['acc'])
hist= model.fit(x_train, y_train, epochs=200, batch_size=650, validation_data=(x_test, y_test), verbose=1)

import matplotlib.pyplot as plt
training_accuracy = hist.history['acc']
acuracia_teste = hist.history['val_acc']
epochs = range(1, len(training_accuracy)+1)
plt.plot(epochs, training_accuracy, '-g', label= 'Training accuracy')
plt.plot(epochs, acuracia_teste, '-b', label= 'Test accuracy')
plt.legend()
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.show()

# Make predictions about the test set
predictions = model.predict(x_test)
#print(predictions)

# Convert predictions into classes (assuming that predictions are probabilities)
predicted_classes = np.argmax(predictions, axis=1)
# Get the actual classes of the test set
real_classes = np.argmax(y_test, axis=1)

import sklearn
from sklearn.metrics import matthews_corrcoef
matthews_corrcoef(real_classes, predicted_classes)

# Create the confusion matrix
matrix = confusion_matrix(real_classes, predicted_classes)

print(matrix)

import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score
from statsmodels.stats.proportion import proportion_confint

# Calculate metrics and confidence intervals
accuracy = accuracy_score(real_classes, predicted_classes)
auc = roc_auc_score(real_classes, predictions[:, 1])
f1 = f1_score(real_classes, predicted_classes)
precision = precision_score(real_classes, predicted_classes)
recall = recall_score(real_classes, predicted_classes)

accuracy_ci = proportion_confint(count=accuracy * len(real_classes), nobs=len(real_classes), alpha=0.05, method='wilson')
auc_ci = proportion_confint(count=int(auc * len(real_classes)), nobs=len(real_classes), alpha=0.05, method='wilson')
f1_ci = proportion_confint(count=int(f1 * len(real_classes)), nobs=len(real_classes), alpha=0.05, method='wilson')
precision_ci = proportion_confint(count=int(precision * len(real_classes)), nobs=len(real_classes), alpha=0.05, method='wilson')
recall_ci = proportion_confint(count=int(recall * len(real_classes)), nobs=len(real_classes), alpha=0.05, method='wilson')

# Create heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(matrix, annot=True, fmt='d', cmap='coolwarm', cbar=True)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')

# Add numbers and percentages inside cells
total = np.sum(matrix)
labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
for i in range(matrix.shape[0]):
  for j in range(matrix.shape[1]):
    plt.text(j + 0.5, i + 0.4, labels[i * 2 + j], ha='center', va='center', color='white')
    plt.text(j + 0.5, i + 0.6, '{:.1f}%'.format(matrix[i, j] / total * 100),
             ha='center', va='center', color='white')

# Add metrics and confidence intervals below x-axis label
plt.text(0.5, -0.20, 'AUC: {:.1f}% ({:.1f}% - {:.1f}%)'.format(auc * 100, auc_ci[0] * 100, auc_ci[1] * 100),
         ha='center', va='top', transform=plt.gca().transAxes)
plt.text(0.5, -0.15, 'Accuracy: {:.1f}% ({:.1f}% - {:.1f}%)'.format(accuracy * 100, accuracy_ci[0] * 100, accuracy_ci[1] * 100),
         ha='center', va='top', transform=plt.gca().transAxes)
plt.text(0.5, -0.25, 'F1 Score: {:.1f}% ({:.1f}% - {:.1f}%)'.format(f1 * 100, f1_ci[0] * 100, f1_ci[1] * 100),
         ha='center', va='top', transform=plt.gca().transAxes)
plt.text(0.5, -0.30, 'Precision: {:.1f}% ({:.1f}% - {:.1f}%)'.format(precision * 100, precision_ci[0] * 100, precision_ci[1] * 100),
         ha='center', va='top', transform=plt.gca().transAxes)
plt.text(0.5, -0.35, 'Recall: {:.1f}% ({:.1f}% - {:.1f}%)'.format(recall * 100, recall_ci[0] * 100, recall_ci[1] * 100),
         ha='center', va='top', transform=plt.gca().transAxes)

import matplotlib.pyplot as plt

def draw_detailed_neural_network(layers, activations):
    fig, ax = plt.subplots(figsize=(12, 8))

    # Calculate positions
    left = 0.1
    right = 0.9
    bottom = 0.1
    top = 0.9
    v_spacing = (top - bottom) / float(max(layers))
    h_spacing = (right - left) / float(len(layers) - 1)

    # Nodes
    for i, layer in enumerate(layers):
        layer_top = v_spacing * (layer - 1) / 2. + (top + bottom) / 2.
        for j in range(layer):
            circle = plt.Circle((i * h_spacing + left, layer_top - j * v_spacing), v_spacing / 4.,
                                color='lightblue', ec='k', zorder=4)  # Change node color to light blue
            ax.add_artist(circle)

    # Edges
    for i, (layer_size_a, layer_size_b) in enumerate(zip(layers[:-1], layers[1:])):
        layer_top_a = v_spacing * (layer_size_a - 1) / 2. + (top + bottom) / 2.
        layer_top_b = v_spacing * (layer_size_b - 1) / 2. + (top + bottom) / 2.
        for j in range(layer_size_a):
            for k in range(layer_size_b):
                line = plt.Line2D([i * h_spacing + left, (i + 1) * h_spacing + left],
                                  [layer_top_a - j * v_spacing, layer_top_b - k * v_spacing], c='lightblue')
                ax.add_artist(line)

    # Layer labels
    for i, layer in enumerate(layers):
        if i == 0:
            ax.text(i * h_spacing + left, top + 0.05, f'Input Layer\n({layer} neurons)', horizontalalignment='center', fontsize=12, zorder=5)
        elif i == len(layers) - 1:
            ax.text(i * h_spacing + left, top + 0.05, f'Output Layer\n({layer} neurons)\n{activations[i]}', horizontalalignment='center', fontsize=12, zorder=5)
        else:
            ax.text(i * h_spacing + left, top + 0.05, f'Hidden Layer {i}\n({layer} neurons)\n{activations[i]}', horizontalalignment='center', fontsize=12, zorder=5)

    ax.axis('off')
    plt.show()

# Define the layers and activations based on the neural network structure
layers = [67, 40, 20, 20, 20, 2]
activations = ['', 'ReLU', 'ReLU', 'ReLU', 'ReLU', 'Sigmoid']

# Draw the detailed neural network with activations
draw_detailed_neural_network(layers, activations)

# Values from (Orange 3) Bayes
tn = 2199
fp = 84
fn = 4
tp = 208

# Calculate sensitivity
sensitivity = tp / (tp + fn)

# Calculate specificity
specificity = tn / (tn + fp)

# Calculate the area under the curve (AUC)
auc = 0.509 * (sensitivity + specificity)

# Calculate the standard error
se = np.sqrt((auc * (1 - auc)) / (tp + fn + fp + tn))

# Calculate the 95% confidence interval
lower_ci = auc - 1.96 * se
upper_ci = auc + 1.96 * se

# Calculate accuracy
OBayes_accuracy = (tp + tn) / (tp + tn + fp + fn)

# Calculate the standard error for accuracy
se_OBayes_accuracy = np.sqrt((OBayes_accuracy * (1 - OBayes_accuracy)) / (tp + tn + fp + fn))

# Calculate the 95% confidence interval for accuracy
lower_ci_accuracy = OBayes_accuracy - 1.96 * se_OBayes_accuracy
upper_ci_accuracy = OBayes_accuracy + 1.96 * se_OBayes_accuracy

# Calculate F1 score
f1_score = (2 * tp) / ((2 * tp) + fp + fn)

# Calculate precision
precision = tp / (tp + fp)

# Calculate recall
recall = tp / (tp + fn)

# Calculate standard errors and confidence intervals
se_f1 = np.sqrt((f1_score * (1 - f1_score)) / (tp + fn + fp + tn))
lower_ci_f1 = f1_score - 1.96 * se_f1
upper_ci_f1 = f1_score + 1.96 * se_f1

se_precision = np.sqrt((precision * (1 - precision)) / (tp + fp))
lower_ci_precision = precision - 1.96 * se_precision
upper_ci_precision = precision + 1.96 * se_precision

se_recall = np.sqrt((recall * (1 - recall)) / (tp + fn))
lower_ci_recall = recall - 1.96 * se_recall
upper_ci_recall = recall + 1.96 * se_recall

# Print results
print ("Values for Na√Øves Bayes model from Orange 3")
print("AUC= {:.1%} ({:.1%} - {:.1%})".format(auc, lower_ci, upper_ci))
print("Accuracy= {:.1%} ({:.1%} - {:.1%})".format(OBayes_accuracy, lower_ci, upper_ci))
print("F1 Score= {:.1%} ({:.1%} - {:.1%})".format(f1_score, lower_ci_f1, upper_ci_f1))
print("Precision= {:.1%} ({:.1%} - {:.1%})".format(precision, lower_ci_precision, upper_ci_precision))
print("Recall= {:.1%} ({:.1%} - {:.1%})".format(recall, lower_ci_recall, upper_ci_recall))

# Values from (Orange 3) Neural Network
tn = 2269
fp = 14
fn = 19
tp = 193

# Calculate sensitivity
sensitivity = tp / (tp + fn)

# Calculate specificity
specificity = tn / (tn + fp)

# Calculate the area under the curve (AUC)
auc = 0.5205 * (sensitivity + specificity)
# Calculate the standard error and the 95% confidence interval
se = np.sqrt((auc * (1 - auc)) / (tp + fn + fp + tn))
lower_ci = auc - 1.96 * se
upper_ci = auc + 1.96 * se

# Calculate accuracy
accuracy = (tp + tn) / (tp + tn + fp + fn)
# Calculate the standard error for accuracy and the 95% confidence interval
se_accuracy = np.sqrt((accuracy * (1 - accuracy)) / (tp + tn + fp + fn))
lower_ci_accuracy = accuracy - 1.96 * se_accuracy
upper_ci_accuracy = accuracy + 1.96 * se_accuracy

# Calculate F1 score
f1_score = (2 * tp) / ((2 * tp) + fp + fn)
# Calculate standard errors and confidence intervals of F1 score
se_f1 = np.sqrt((f1_score * (1 - f1_score)) / (tp + fn + fp + tn))
lower_ci_f1 = f1_score - 1.96 * se_f1
upper_ci_f1 = f1_score + 1.96 * se_f1


# Calculate precision
precision = tp / (tp + fp)
# Calculate standard errors and confidence intervals of precision
se_precision = np.sqrt((precision * (1 - precision)) / (tp + fp))
lower_ci_precision = precision - 1.96 * se_precision
upper_ci_precision = precision + 1.96 * se_precision

# Calculate recall
recall = tp / (tp + fn)
# Calculate standard errors and confidence intervals of recal
se_recall = np.sqrt((recall * (1 - recall)) / (tp + fn))
lower_ci_recall = recall - 1.96 * se_recall
upper_ci_recall = recall + 1.96 * se_recall

# Print results
print ("Values for Neural Network model from Orange 3")
print("AUC= {:.1%} ({:.1%} - {:.1%})".format(auc, lower_ci, upper_ci))
print("Accuracy={:.1%} ({:.1%} - {:.1%})".format(accuracy, lower_ci_accuracy, upper_ci_accuracy))
print("F1 Score={:.1%} ({:.1%} - {:.1%})".format(f1_score, lower_ci_f1, upper_ci_f1))
print("Precision={:.1%} ({:.1%} - {:.1%})".format(precision, lower_ci_precision, upper_ci_precision))
print("Recall={:.1%} ({:.1%} - {:.1%})".format(recall, lower_ci_recall, upper_ci_recall))